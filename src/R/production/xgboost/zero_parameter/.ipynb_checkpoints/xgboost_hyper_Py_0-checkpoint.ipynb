{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cac7fb33684f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m  \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m   \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m   \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pandas  as pd\n",
    "import numpy   as np\n",
    "from   sklearn.model_selection import KFold\n",
    "import optuna\n",
    "import time\n",
    "import json\n",
    "from   optuna.samplers import TPESampler\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_import(data_name):\n",
    "    filename = 'https://raw.githubusercontent.com/avinashbarnwal/GSOC-2019/master/AFT/test/data/'+data_name+'/'\n",
    "    inputFileName = filename+'inputs.csv'\n",
    "    labelFileName = filename+'outputs.csv'\n",
    "    foldsFileName = filename+'cv/equal_labels/folds.csv'\n",
    "    inputs        = pd.read_csv(inputFileName,index_col='sequenceID')\n",
    "    labels        = pd.read_csv(labelFileName,index_col='sequenceID')\n",
    "    folds         = pd.read_csv(foldsFileName,index_col='sequenceID')\n",
    "    res           = {}\n",
    "    res['inputs'] = inputs\n",
    "    res['labels'] = labels\n",
    "    res['folds']  = folds\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_massage(inputs,labels):\n",
    "    inputs.replace([-float('inf'),float('inf')],np.nan,inplace=True)\n",
    "    missingCols = inputs.isnull().sum()\n",
    "    missingCols = list(missingCols[missingCols>0].index)\n",
    "    inputs.drop(missingCols,axis=1,inplace=True)\n",
    "    varCols     = inputs.apply(lambda x: np.var(x))\n",
    "    zeroVarCols = list(varCols[varCols==0].index)\n",
    "    inputs.drop(zeroVarCols,axis=1,inplace=True)\n",
    "    labels['min.log.lambda'] = labels['min.log.lambda'].apply(lambda x: np.exp(x))\n",
    "    labels['max.log.lambda'] = labels['max.log.lambda'].apply(lambda x: np.exp(x))\n",
    "    return inputs,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXY(foldNo,folds,inputs,labels):\n",
    "    test_id       = list(folds[folds['fold']==foldNo].index)\n",
    "    train_id      = list(folds[folds['fold']!=foldNo].index)\n",
    "    X             = inputs[inputs.index.isin(train_id)]\n",
    "    X_val         = inputs[inputs.index.isin(test_id)]\n",
    "    y_label       = labels[labels.index.isin(train_id)]\n",
    "    y_label_test  = labels[labels.index.isin(test_id)]\n",
    "    y_lower       = y_label['min.log.lambda']\n",
    "    y_upper       = y_label['max.log.lambda']\n",
    "    y_lower_val   = y_label_test['min.log.lambda']\n",
    "    y_upper_val   = y_label_test['max.log.lambda']\n",
    "    res           = {}\n",
    "    res['X']         = X\n",
    "    res['X_val']     = X_val\n",
    "    res['y_lower']      = y_lower\n",
    "    res['y_lower_val']  = y_lower_val\n",
    "    res['y_upper']      = y_upper\n",
    "    res['y_upper_val']  = y_upper_val\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(X,X_val,y_lower,y_upper,y_lower_val,y_upper_val,params,num_round,distributionCol):\n",
    "    \n",
    "    res    = {}\n",
    "    dtrain = xgb.DMatrix(X)\n",
    "    dtrain.set_float_info(\"label_lower_bound\",y_lower.values)\n",
    "    dtrain.set_float_info(\"label_upper_bound\",y_upper.values)\n",
    "\n",
    "    dtest  = xgb.DMatrix(X_val)\n",
    "    dtest.set_float_info(\"label_lower_bound\",y_lower_val.values)\n",
    "    dtest.set_float_info(\"label_upper_bound\",y_upper_val.values)\n",
    "    \n",
    "    bst    = xgb.train(params,dtrain,num_boost_round=num_round,evals=[(dtrain,\"train\"),(dtest,\"test\")],evals_result=res,verbose_eval=False)\n",
    "    min_val_error = round(np.min(res['test'][distributionCol]),4)\n",
    "    return(min_val_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(distribution,trial):\n",
    "    \n",
    "    SEED         = 1\n",
    "    Kfolds       = KFold(n_splits=5,shuffle=True,random_state=SEED)\n",
    "    num_round    = 5000\n",
    "    res          = 0\n",
    "    \n",
    "    eta              = trial.suggest_discrete_uniform('eta',0.001,1.001,0.1)\n",
    "    max_depth        = trial.suggest_discrete_uniform('max_depth',2, 10,2)\n",
    "    \n",
    "#     min_child_weight = trial.suggest_discrete_uniform('min_child_weight',0.1,100.1,10)\n",
    "#     reg_alpha        = trial.suggest_loguniform('reg_alpha',0.0001,100)\n",
    "#     reg_lambda       = trial.suggest_loguniform('reg_lambda',0.0001,100)\n",
    "\n",
    "    min_child_weight = 0.1\n",
    "    reg_alpha        = 0.005\n",
    "    reg_lambda       = 0.5\n",
    "    \n",
    "    if distribution in ['normal','logistic']:\n",
    "        sigma  = 1\n",
    "    else:\n",
    "        sigma  = 10\n",
    "    \n",
    "    distribution_sigma = distribution+ ',' + str(sigma)\n",
    "    eval_metric     = 'aft-nloglik@'+distribution_sigma\n",
    "    base_score      = 0.5\n",
    "    \n",
    "    params   = {\n",
    "                'eta':eta,\n",
    "                'max_depth':int(max_depth),\n",
    "                'min_child_weight':min_child_weight,\n",
    "                'subsample':0.7,\n",
    "                'reg_alpha':reg_alpha,\n",
    "                'reg_lambda':reg_lambda,\n",
    "                'aft_noise_distribution' : distribution, \n",
    "                'aft_sigma': sigma,\n",
    "                'eval_metric':eval_metric,\n",
    "                'base_score':base_score,\n",
    "                'objective':\"aft:survival\",\n",
    "                'verbosity': 0\n",
    "                }\n",
    "    \n",
    "    for fold_, (trn_idx, val_idx) in enumerate(Kfolds.split(X, y_lower,y_upper)):\n",
    "        tr_x, tr_y_lower,tr_y_upper = X.iloc[trn_idx,:],y_lower.iloc[trn_idx],y_upper.iloc[trn_idx]\n",
    "        vl_x, vl_y_lower,vl_y_upper = X.iloc[val_idx,:], y_lower.iloc[val_idx],y_upper.iloc[val_idx]\n",
    "        res = res + trainModel(tr_x,vl_x,tr_y_lower,tr_y_upper,vl_y_lower,vl_y_upper,params,num_round,distribution_sigma)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "num_round    = 5000\n",
    "eta          = 0.01\n",
    "max_depth    = 4\n",
    "min_child_weight = 0.1\n",
    "reg_alpha        = 0.005\n",
    "reg_lambda       = 0.5\n",
    "if distribution in ['normal','logistic']:\n",
    "    sigma  = 1\n",
    "else:\n",
    "    sigma  = 10\n",
    "distribution_sigma = distribution+ ',' + str(sigma)\n",
    "eval_metric     = 'aft-nloglik@'+distribution_sigma\n",
    "base_score      = 0.5\n",
    "params   = {\n",
    "            'eta':eta,\n",
    "            'max_depth':int(max_depth),\n",
    "            'min_child_weight':min_child_weight,\n",
    "            'subsample':0.7,\n",
    "            'reg_alpha':reg_alpha,\n",
    "            'reg_lambda':reg_lambda,\n",
    "            'aft_noise_distribution' : distribution, \n",
    "            'aft_sigma': sigma,\n",
    "            'eval_metric':eval_metric,\n",
    "            'base_score':base_score,\n",
    "            'objective':\"aft:survival\",\n",
    "            'random_state':1,\n",
    "            'verbosity': 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name_domain = ['ATAC_JV_adipose','CTCF_TDH_ENCODE','H3K27ac-H3K4me3_TDHAM_BP','H3K27ac_TDH_some','H3K36me3_AM_immune']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data      = data_import(data_name_domain[0])\n",
    "data_name = data_name_domain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = data['inputs']\n",
    "labels = data['labels']\n",
    "folds  = data['folds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs,labels = data_massage(inputs,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "global X\n",
    "global X_val\n",
    "global y_lower\n",
    "global y_upper\n",
    "global y_upper_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_time = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModelIter(X,X_val,y_lower,y_upper,y_lower_val,y_upper_val,params,num_round,distributionCol):\n",
    "    \n",
    "    res    = {}\n",
    "    dtrain = xgb.DMatrix(X)\n",
    "    dtrain.set_float_info(\"label_lower_bound\",y_lower)\n",
    "    dtrain.set_float_info(\"label_upper_bound\",y_upper)\n",
    "\n",
    "    dtest  = xgb.DMatrix(X_val)\n",
    "    dtest.set_float_info(\"label_lower_bound\",y_lower_val)\n",
    "    dtest.set_float_info(\"label_upper_bound\",y_upper_val)\n",
    "\n",
    "    bst       = xgb.train(params,dtrain,num_boost_round=num_round,evals=[(dtrain,\"train\"),(dtest,\"test\")],evals_result=res,verbose_eval=False)\n",
    "    val_error = res['test'][distributionCol]\n",
    "    \n",
    "    res_data['total'] = res_data.sum(axis=1)\n",
    "\n",
    "    num_round = res_data.idxmin(axis=0, skipna=True)['total']\n",
    "    res['num_round'] = num_round\n",
    "    res['min_val_error'] = min(res_data['total'])\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for fold in range(2,3):\n",
    "for fold in np.unique(folds['fold'].values):\n",
    "    \n",
    "    start_time   = time.time()\n",
    "    res = getXY(fold,folds,inputs,labels)\n",
    "    X            = res['X']        \n",
    "    X_val        = res['X_val']\n",
    "    y_lower      = res['y_lower']\n",
    "    y_lower_val  = res['y_lower_val']\n",
    "    y_upper      = res['y_upper']\n",
    "    y_upper_val  = res['y_upper_val']\n",
    "    \n",
    "    for distribution in ['normal','logistic','extreme']:\n",
    "        key = str(fold)+\"_\"+distribution\n",
    "        trainModelIter(X,X_val,y_lower,y_upper,y_lower_val,y_upper_val,params,num_round,distributionCol)\n",
    "        json_filename = \"../../../../result/\"+data_name+\"/xgboost/fold\"+str(fold)+'_'+distribution+'_param.json'\n",
    "        with open(json_filename, \"w\") as write_file:\n",
    "            json.dump(trial.params, write_file)\n",
    "    end_time        = time.time()\n",
    "    time_taken      = end_time - start_time\n",
    "    run_time2[fold] = time_taken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing best hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_time3 ={}\n",
    "for key in run_time2.keys():\n",
    "    run_time3[str(key)] = run_time2[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_filename = \"../../../../../result/\"+data_name+\"/xgboost/run_time_2_param_tuning2.json\"\n",
    "with open(json_filename, \"w\") as write_file:\n",
    "    json.dump(run_time3, write_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
