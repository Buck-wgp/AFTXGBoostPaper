{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas  as pd\n",
    "import numpy   as np\n",
    "from   sklearn.model_selection import KFold\n",
    "import optuna\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_import(data_name):\n",
    "    filename = 'https://raw.githubusercontent.com/avinashbarnwal/GSOC-2019/master/AFT/test/data/neuroblastoma-data-master/data/'+data_name+'/'\n",
    "    inputFileName = filename+'inputs.csv'\n",
    "    labelFileName = filename+'outputs.csv'\n",
    "    foldsFileName = filename+'cv/equal_labels/folds.csv'\n",
    "    inputs        = pd.read_csv(inputFileName,index_col='sequenceID')\n",
    "    labels        = pd.read_csv(labelFileName,index_col='sequenceID')\n",
    "    folds         = pd.read_csv(foldsFileName,index_col='sequenceID')\n",
    "    res           = {}\n",
    "    res['inputs'] = inputs\n",
    "    res['labels'] = labels\n",
    "    res['folds']  = folds\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_massage(inputs,labels):\n",
    "    inputs.replace([-float('inf'),float('inf')],np.nan,inplace=True)\n",
    "    missingCols = inputs.isnull().sum()\n",
    "    missingCols = list(missingCols[missingCols>0].index)\n",
    "    inputs.drop(missingCols,axis=1,inplace=True)\n",
    "    varCols     = inputs.apply(lambda x: np.var(x))\n",
    "    zeroVarCols = list(varCols[varCols==0].index)\n",
    "    inputs.drop(zeroVarCols,axis=1,inplace=True)\n",
    "    labels['min.log.lambda'] = labels['min.log.lambda'].apply(lambda x: np.exp(x))\n",
    "    labels['max.log.lambda'] = labels['max.log.lambda'].apply(lambda x: np.exp(x))\n",
    "    return inputs,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXY(foldNo,folds,inputs,labels):\n",
    "    test_id       = list(folds[folds['fold']==foldNo].index)\n",
    "    train_id      = list(folds[folds['fold']!=foldNo].index)\n",
    "    X             = inputs[inputs.index.isin(train_id)]\n",
    "    X_val         = inputs[inputs.index.isin(test_id)]\n",
    "    y_label       = labels[labels.index.isin(train_id)]\n",
    "    y_label_test  = labels[labels.index.isin(test_id)]\n",
    "    y_lower       = y_label['min.log.lambda']\n",
    "    y_upper       = y_label['max.log.lambda']\n",
    "    y_lower_val   = y_label_test['min.log.lambda']\n",
    "    y_upper_val   = y_label_test['max.log.lambda']\n",
    "    res           = {}\n",
    "    res['X']         = X\n",
    "    res['X_val']     = X_val\n",
    "    res['y_lower']      = y_lower\n",
    "    res['y_lower_val']  = y_lower_val\n",
    "    res['y_upper']      = y_upper\n",
    "    res['y_upper_val']  = y_upper_val\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(X,X_val,y_lower,y_upper,y_lower_val,y_upper_val,params,num_round,distributionCol):\n",
    "    res    = {}\n",
    "    dtrain = xgb.DMatrix(X)\n",
    "    dtrain.set_float_info(\"label_lower_bound\",y_lower)\n",
    "    dtrain.set_float_info(\"label_upper_bound\",y_upper)\n",
    "\n",
    "    dtest  = xgb.DMatrix(X_val)\n",
    "    dtest.set_float_info(\"label_lower_bound\",y_lower_val)\n",
    "    dtest.set_float_info(\"label_upper_bound\",y_upper_val)\n",
    "\n",
    "    bst    = xgb.train(params,dtrain,num_boost_round=num_round,evals=[(dtrain,\"train\"),(dtest,\"test\")],evals_result=res,verbose_eval=False)\n",
    "    min_val_error = round(np.min(res['test'][distributionCol]),4)\n",
    "    return(min_val_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'ATAC_JV_adipose'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    SEED         = 1\n",
    "    Kfolds       = KFold(n_splits=5,shuffle=True,random_state=SEED)\n",
    "    num_round    = 1000\n",
    "    res          = 0\n",
    "    # Discrete-uniform parameter\n",
    "    eta              = trial.suggest_discrete_uniform('eta',0.001,1.001,0.1)\n",
    "    max_depth        = trial.suggest_discrete_uniform('max_depth',2, 10,2)\n",
    "    min_child_weight = trial.suggest_discrete_uniform('min_child_weight',0.1,100.1,10)\n",
    "    reg_alpha        = trial.suggest_loguniform('reg_alpha',0.0001,100)\n",
    "    reg_lambda       = trial.suggest_loguniform('reg_lambda',0.0001,100)\n",
    "    sigma            = trial.suggest_discrete_uniform('sigma',1,100,1)\n",
    "    distribution     = trial.suggest_categorical('distribution',['normal','logistic','extreme'])\n",
    "    \n",
    "    distributionCol = distribution+ ',' + str(sigma)\n",
    "    eval_metric     = 'aft-nloglik@'+distributionCol\n",
    "    base_score      = 0.5\n",
    "    \n",
    "    params   = {\n",
    "                'eta':eta,\n",
    "                'max_depth':int(max_depth),\n",
    "                'min_child_weight':min_child_weight,\n",
    "                'subsample':0.7,\n",
    "                'reg_alpha':reg_alpha,\n",
    "                'reg_lambda':reg_lambda,\n",
    "                'aft_noise_distribution' : distribution, \n",
    "                'aft_sigma': sigma,\n",
    "                'eval_metric':eval_metric,\n",
    "                'base_score':base_score,\n",
    "                'objective':\"aft:survival\",\n",
    "                'verbosity': 0\n",
    "                }\n",
    "    \n",
    "    for fold_, (trn_idx, val_idx) in enumerate(Kfolds.split(X, y_lower,y_upper)):\n",
    "        tr_x, tr_y_lower,tr_y_upper = X.iloc[trn_idx,:],y_lower.iloc[trn_idx],y_upper.iloc[trn_idx]\n",
    "        vl_x, vl_y_lower,vl_y_upper = X.iloc[val_idx,:], y_lower.iloc[val_idx],y_upper.iloc[val_idx]\n",
    "        res = res + trainModel(tr_x,vl_x,tr_y_lower,tr_y_upper,vl_y_lower,vl_y_upper,params,num_round,distributionCol)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_import(data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = data['inputs']\n",
    "labels = data['labels']\n",
    "folds  = data['folds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs,labels = data_massage(inputs,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "global X\n",
    "global X_val\n",
    "global y_lower\n",
    "global y_upper\n",
    "global y_upper_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in np.unique(folds['fold'].values):\n",
    "    res          = getXY(fold,folds,inputs,labels)\n",
    "    X            = res['X']        \n",
    "    X_val        = res['X_val']\n",
    "    y_lower      = res['y_lower']\n",
    "    y_lower_val  = res['y_lower_val']\n",
    "    y_upper      = res['y_upper']\n",
    "    y_upper_val  = res['y_upper_val']\n",
    "    study        = optuna.create_study()\n",
    "    start        = time.time()\n",
    "    study.optimize(objective, n_trials=1)\n",
    "    trial        = study.best_trial\n",
    "    json_filename = \"../../../../result/\"+data_name+\"/fold\"+str(fold)+'_param.json'\n",
    "    with open(json_filename, \"w\") as write_file:\n",
    "        json.dump(trial.params, write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_iter(eta,max_depth,min_child_weight,reg_alpha,reg_lambda,sigma,distribution):   \n",
    "    folds        = KFold(n_splits=5,shuffle=True,random_state=SEED)\n",
    "    num_round    = 5000\n",
    "    # Discrete-uniform parameter\n",
    "    distributionCol = distribution+ ',' + str(sigma)\n",
    "    eval_metric     = 'aft-nloglik@'+distributionCol\n",
    "    base_score      = 0.5\n",
    "    \n",
    "    params   = {\n",
    "                'eta':eta,\n",
    "                'max_depth':int(max_depth),\n",
    "                'min_child_weight':min_child_weight,\n",
    "                'subsample':0.7,\n",
    "                'reg_alpha':reg_alpha,\n",
    "                'reg_lambda':reg_lambda,\n",
    "                'aft_noise_distribution' : distribution, \n",
    "                'aft_sigma': sigma,\n",
    "                'eval_metric':eval_metric,\n",
    "                'base_score':base_score,\n",
    "                'objective':\"aft:survival\",\n",
    "                'verbosity': 0\n",
    "                }\n",
    "    res_data = pd.DataFrame()\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(Kfolds.split(X, y_lower,y_upper)):\n",
    "        tr_x, tr_y_lower,tr_y_upper = X.iloc[trn_idx,:],y_lower.iloc[trn_idx],y_upper.iloc[trn_idx]\n",
    "        vl_x, vl_y_lower,vl_y_upper = X.iloc[val_idx,:], y_lower.iloc[val_idx],y_upper.iloc[val_idx]\n",
    "        res_data[fold_] = trainModelIter(tr_x,vl_x,tr_y_lower,tr_y_upper,vl_y_lower,vl_y_upper,params,num_round,distributionCol)\n",
    "    res_data['total'] = res_data.sum(axis=1)\n",
    "    num_round = res_data.idxmin(axis=0, skipna=True)['total']\n",
    "    return num_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModelIter(X,X_val,y_lower,y_upper,y_lower_val,y_upper_val,params,num_round,distributionCol):\n",
    "    \n",
    "    res    = {}\n",
    "    dtrain = xgb.DMatrix(X)\n",
    "    dtrain.set_float_info(\"label_lower_bound\",y_lower)\n",
    "    dtrain.set_float_info(\"label_upper_bound\",y_upper)\n",
    "\n",
    "    dtest  = xgb.DMatrix(X_val)\n",
    "    dtest.set_float_info(\"label_lower_bound\",y_lower_val)\n",
    "    dtest.set_float_info(\"label_upper_bound\",y_upper_val)\n",
    "\n",
    "    bst    = xgb.train(params,dtrain,num_boost_round=num_round,evals=[(dtrain,\"train\"),(dtest,\"test\")],evals_result=res,verbose_eval=False)\n",
    "    val_error = res['test'][distributionCol]\n",
    "    return(val_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eta': 0.501, 'max_depth': 2.0, 'min_child_weight': 10.1, 'reg_alpha': 0.0007365616343363529, 'reg_lambda': 0.006008420772700877, 'sigma': 1.0, 'distribution': 'normal', 'num_round': 15}\n",
      "{'eta': 0.501, 'max_depth': 2.0, 'min_child_weight': 10.1, 'reg_alpha': 0.02466196017528009, 'reg_lambda': 0.0001435631631837924, 'sigma': 1.0, 'distribution': 'normal', 'num_round': 30}\n",
      "{'eta': 0.501, 'max_depth': 2.0, 'min_child_weight': 40.1, 'reg_alpha': 0.00040991206401592176, 'reg_lambda': 0.9814693531342946, 'sigma': 1.0, 'distribution': 'normal', 'num_round': 40}\n",
      "{'eta': 0.001, 'max_depth': 2.0, 'min_child_weight': 70.1, 'reg_alpha': 0.01730709280898488, 'reg_lambda': 0.9611466118791246, 'sigma': 1.0, 'distribution': 'normal', 'num_round': 4999}\n"
     ]
    }
   ],
   "source": [
    "#for fold in range(2,3):\n",
    "for fold in np.unique(folds['fold'].values):\n",
    "    res = getXY(fold,folds,inputs,labels)\n",
    "    X            = res['X']        \n",
    "    X_val        = res['X_val']\n",
    "    y_lower      = res['y_lower']\n",
    "    y_lower_val  = res['y_lower_val']\n",
    "    y_upper      = res['y_upper']\n",
    "    y_upper_val  = res['y_upper_val']\n",
    "    json_filename = \"fold\"+str(fold)+'_param.json'\n",
    "    with open(json_filename, errors='ignore') as json_data:\n",
    "        json_fold = json.load(json_data, strict=False)\n",
    "    eta = json_fold['eta']\n",
    "    max_depth = json_fold['max_depth']\n",
    "    min_child_weight = json_fold['min_child_weight']\n",
    "    reg_alpha = json_fold['reg_alpha']\n",
    "    reg_lambda = json_fold['reg_lambda']\n",
    "    sigma= json_fold['sigma']\n",
    "    distribution = json_fold['distribution'] \n",
    "    num_round = best_iter(eta,max_depth,min_child_weight,reg_alpha,reg_lambda,sigma,distribution)\n",
    "    new_json = {}\n",
    "    new_json['eta'] = eta\n",
    "    new_json['max_depth'] = max_depth\n",
    "    new_json['min_child_weight'] = min_child_weight\n",
    "    new_json['reg_alpha'] = reg_alpha\n",
    "    new_json['reg_lambda'] = reg_lambda\n",
    "    new_json['sigma'] = sigma\n",
    "    new_json['distribution'] = distribution\n",
    "    new_json['num_round'] = int(num_round)\n",
    "    json_filename = \"fold_new\"+str(fold)+'_param.json'\n",
    "    with open(json_filename, \"w\") as write_file:\n",
    "         json.dump(new_json, write_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
