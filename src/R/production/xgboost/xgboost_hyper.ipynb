{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caret)\n",
    "library(xgboost)\n",
    "#library(MlBayesOpt)\n",
    "library(Matrix)\n",
    "library(rBayesianOptimization)\n",
    "#https://gitlab.com/avinashbarnwal/elokaggle/blob/master/code/304_hyperparameter_optuna.ipynb\n",
    "#https://gitlab.com/avinashbarnwal/elokaggle/blob/master/code/302_LGBM_BO_hyperpara.ipynb\n",
    "#https://cran.r-project.org/web/packages/MlBayesOpt/vignettes/MlBayesOpt.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_import =function(dataname){\n",
    "  filename = paste('https://raw.githubusercontent.com/avinashbarnwal/GSOC-2019/master/AFT/test/data/neuroblastoma-data-master/data/',dataname,'/',sep=\"\")\n",
    "  inputFileName = paste(filename,'inputs.csv',sep=\"\")\n",
    "  labelFileName = paste(filename,'outputs.csv',sep=\"\")\n",
    "  foldsFileName = paste(filename,'cv/equal_labels/folds.csv',sep=\"\")\n",
    "  inputs        = read.table(inputFileName,sep=\",\",header=T,stringsAsFactors = F,row.names=1)\n",
    "  labels        = read.table(labelFileName,sep=\",\",header=T,stringsAsFactors = F,row.names=1)\n",
    "  folds         = read.table(foldsFileName,sep=\",\",header=T,stringsAsFactors = F,row.names=1)\n",
    "  res           = list()\n",
    "  res$inputs    = inputs\n",
    "  res$labels    = labels\n",
    "  res$folds     = folds\n",
    "  return(res)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_massage = function(inputs,labels){\n",
    "    rownamesInput = rownames(inputs)\n",
    "    inputs        = do.call(data.frame,lapply(inputs, function(x) replace(x, is.infinite(x),NA)))\n",
    "    naColumns     = colnames(inputs)[colSums(is.na(inputs))>0]\n",
    "    noVarCol      = getNonVarCols(inputs)\n",
    "    removeCols    = c(naColumns,noVarCol)\n",
    "    inputs        = inputs[ , !(colnames(inputs) %in% removeCols)]\n",
    "    rownames(inputs) = rownamesInput\n",
    "    labels$min.log.lambda = unlist(lapply(labels$min.log.lambda,exp))\n",
    "    labels$max.log.lambda = unlist(lapply(labels$max.log.lambda,exp))\n",
    "    res        = list()\n",
    "    res$inputs = inputs\n",
    "    res$labels = labels\n",
    "    return(res)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "getXY<-function(foldNo,folds,inputs,labels){\n",
    "    test.id       = rownames(subset(folds,fold==foldNo))\n",
    "    train.id      = rownames(subset(folds,fold!=foldNo))\n",
    "    X             = subset(inputs,rownames(inputs) %in% train.id)\n",
    "    X             = as.matrix(X)\n",
    "    X.val         = subset(inputs,rownames(inputs) %in% test.id)\n",
    "    X.val         = as.matrix(X.val)\n",
    "    y.label       = subset(labels,rownames(labels) %in% train.id)\n",
    "    y.label.test  = subset(labels,rownames(labels) %in% test.id)\n",
    "    y.lower       = as.matrix(y.label$min.log.lambda)\n",
    "    y.upper       = as.matrix(y.label$max.log.lambda)\n",
    "    y.lower.val   = as.matrix(y.label.test$min.log.lambda)\n",
    "    y.upper.val   = as.matrix(y.label.test$max.log.lambda)\n",
    "    res           = list()\n",
    "    res$X         = X\n",
    "    res$X.val     = X.val\n",
    "    res$y.lower      = y.lower\n",
    "    res$y.lower.val  = y.lower.val\n",
    "    res$y.upper      = y.upper\n",
    "    res$y.upper.val  = y.upper.val\n",
    "    return(res)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "getNonVarCols<-function(data){\n",
    "    var_columns    = apply(inputs,2,var)\n",
    "    resCol         = names(var_columns[var_columns==0.0])\n",
    "    return(resCol)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Parameters\n",
    "dataNameRange       = c('ATAC_JV_adipose','CTCF_TDH_ENCODE','H3K27ac-H3K4me3_TDHAM_BP','H3K27ac_TDH_some','H3K36me3_AM_immune')\n",
    "sigma_range         = c(1,2,5,10,100)\n",
    "distribution_range  = c('normal','logistic','extreme')\n",
    "learning_rate       = 0.1\n",
    "num_round           = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "getaccuracy=function(pred,y_lower,y_higher){\n",
    "    res = (pred>=y_lower & pred<=y_higher)\n",
    "    return(res)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "getParam = function(sigma,distribution,learning_rate){\n",
    "  eval_metric = paste(\"aft-nloglik@\",distribution,\",\",sigma,sep=\"\") \n",
    "  param       = list(learning_rate=learning_rate, aft_noise_distribution=distribution, \n",
    "                    nthread = 4, verbosity=0, aft_sigma= sigma,\n",
    "                    eval_metric  = eval_metric,\n",
    "                    objective  = \"aft:survival\")\n",
    "  return(param)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainModel = function(foldNo,X,X_val,y_lower,y_lower_val,y_upper,y_upper_val,param,num_round){\n",
    "  \n",
    "  dtrain = xgb.DMatrix(X)\n",
    "  setinfo(dtrain,'label_lower_bound', y_lower)\n",
    "  setinfo(dtrain,'label_upper_bound', y_upper)\n",
    "  \n",
    "  dtest = xgb.DMatrix(X_val)\n",
    "  setinfo(dtest,'label_lower_bound', y_lower_val)\n",
    "  setinfo(dtest,'label_upper_bound', y_upper_val)\n",
    "  \n",
    "  watchlist = list(eval = dtest, train = dtrain)\n",
    "  bst       = xgb.train(param, dtrain, num_round, watchlist,verbose = 0)\n",
    "\n",
    "  return(bst)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cv_grid = function(max_depth, min_child_weight, subsample, \n",
    "                        alpha, lambda, nrounds, eta, sigma, distribution,dtrain) {\n",
    "eval_metric = paste(\"aft-nloglik@\",distribution,\",\",sigma,sep=\"\") \n",
    "cv = xgb.cv(params = list(booster = \"gbtree\",\n",
    "                              max_depth = max_depth,min_child_weight = min_child_weight,\n",
    "                              subsample = subsample,alpha = alpha,\n",
    "                              lambda = lambda,nrounds = nrounds,\n",
    "                              learning_rate = learning_rate,\n",
    "                              aft_sigma = sigma,aft_noise_distribution = distribution,\n",
    "                              objective = \"aft:survival\",\n",
    "                              nthread = 4,\n",
    "                              eval_metric = eval_metric),\n",
    "                              data = dtrain,\n",
    "                              nfold = 5, prediction = TRUE, showsd = TRUE,\n",
    "                              early_stopping_rounds = 10, maximize = TRUE, verbose = 0)\n",
    "                              #Score = cv$evaluation_log$test_auc_mean[cv$best_iteration]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_grid         = expand.grid(\n",
    "                                nrounds = 10000,\n",
    "                                eta     = c(0.001,0.01,0.1,0.5,1),\n",
    "                                max_depth = c(2, 4, 6, 8, 10),\n",
    "                                min_child_weight =  c(0.1,10,100), \n",
    "                                subsample        =  0.7,\n",
    "                                alpha            =  c(0.0,0.1,10,100),\n",
    "                                lambda           =  c(0.0001,0.1,10,100),\n",
    "                                sigma            =  c(1,2,5,10,100),\n",
    "                                distribution     =  c('normal','logistic','extreme')\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nParam = dim(xgb_grid)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in xgb.cv(params = list(booster = \"gbtree\", max_depth = max_depth, : Labels must be provided for CV either through xgb.DMatrix, or through 'label=' when 'data' is matrix\n",
     "output_type": "error",
     "traceback": [
      "Error in xgb.cv(params = list(booster = \"gbtree\", max_depth = max_depth, : Labels must be provided for CV either through xgb.DMatrix, or through 'label=' when 'data' is matrix\nTraceback:\n",
      "1. xgb_cv_grid(nrounds, eta, max_depth, min_child_weight, subsample, \n .     alpha, lambda, sigma, distribution, dtrain)",
      "2. xgb.cv(params = list(booster = \"gbtree\", max_depth = max_depth, \n .     min_child_weight = min_child_weight, subsample = subsample, \n .     alpha = alpha, lambda = lambda, nrounds = nrounds, learning_rate = learning_rate, \n .     aft_sigma = sigma, aft_noise_distribution = distribution, \n .     objective = \"aft:survival\", nthread = 4, eval_metric = eval_metric), \n .     data = dtrain, nfold = 5, prediction = TRUE, showsd = TRUE, \n .     early_stopping_rounds = 10, maximize = TRUE, verbose = 0)   # at line 4-15 of file <text>",
      "3. stop(\"Labels must be provided for CV either through xgb.DMatrix, or through 'label=' when 'data' is matrix\")"
     ]
    }
   ],
   "source": [
    "for(i in 1:1){\n",
    "    res                 = data_import(dataNameRange[1])\n",
    "    inputs              = res$inputs\n",
    "    labels              = res$labels\n",
    "    folds               = res$folds\n",
    "    resDataMassage      = data_massage(inputs,labels)\n",
    "    inputs              = resDataMassage$inputs\n",
    "    labels              = resDataMassage$labels\n",
    "    fold_iter           = unique(folds$fold)\n",
    "    accuracy_fold       = numeric(length(fold_iter))\n",
    "    res                 = getXY(fold_iter[i],folds,inputs,labels)\n",
    "    X                   = res$X\n",
    "    X.val               = res$X.val\n",
    "    y.lower             = res$y.lower\n",
    "    y.lower.val         = res$y.lower.val\n",
    "    y.upper             = res$y.upper\n",
    "    y.upper.val         = res$y.upper.val\n",
    "    train.folds         = cut(seq(1,nrow(X)),breaks=5,labels=FALSE)\n",
    "    res                 = list()\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X)\n",
    "    setinfo(dtrain,'label_lower_bound', y.lower)\n",
    "    setinfo(dtrain,'label_upper_bound', y.upper)\n",
    "    \n",
    "    for(i in 1:1){\n",
    "        nrounds   = xgb_grid[i,'nrounds']\n",
    "        eta       = xgb_grid[i,'eta']\n",
    "        max_depth = xgb_grid[i,'max_depth']\n",
    "        min_child_weight =  xgb_grid[i,'min_child_weight']\n",
    "        subsample        =  xgb_grid[i,'subsample']\n",
    "        alpha            =  xgb_grid[i,'alpha']\n",
    "        lambda           =  xgb_grid[i,'lambda']\n",
    "        sigma            =  xgb_grid[i,'sigma']\n",
    "        distribution     =  xgb_grid[i,'distribution']\n",
    "        xgb_cv_grid(nrounds,eta,max_depth,min_child_weight,subsample,alpha,lambda,sigma,distribution,dtrain)\n",
    "}\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
