{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas  as pd\n",
    "import numpy   as np\n",
    "from   sklearn.model_selection import KFold\n",
    "import optuna\n",
    "import time\n",
    "import json\n",
    "from optuna.samplers import TPESampler\n",
    "import functools\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_import(data_name):\n",
    "    filename = '../../../../../../data/'+data_name+'/'\n",
    "    inputFileName = filename+'inputs.csv'\n",
    "    labelFileName = filename+'outputs.csv'\n",
    "    foldsFileName = filename+'cv/equal_labels/folds.csv'\n",
    "    inputs        = pd.read_csv(inputFileName,index_col='sequenceID')\n",
    "    labels        = pd.read_csv(labelFileName,index_col='sequenceID')\n",
    "    folds         = pd.read_csv(foldsFileName,index_col='sequenceID')\n",
    "    res           = {}\n",
    "    res['inputs'] = inputs\n",
    "    res['labels'] = labels\n",
    "    res['folds']  = folds\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_massage(inputs,labels):\n",
    "    inputs.replace([-float('inf'),float('inf')],np.nan,inplace=True)\n",
    "    missingCols = inputs.isnull().sum()\n",
    "    missingCols = list(missingCols[missingCols>0].index)\n",
    "    inputs.drop(missingCols,axis=1,inplace=True)\n",
    "    varCols     = inputs.apply(lambda x: np.var(x))\n",
    "    zeroVarCols = list(varCols[varCols==0].index)\n",
    "    inputs.drop(zeroVarCols,axis=1,inplace=True)\n",
    "    labels['min.log.lambda'] = labels['min.log.lambda'].apply(lambda x: np.exp(x))\n",
    "    labels['max.log.lambda'] = labels['max.log.lambda'].apply(lambda x: np.exp(x))\n",
    "    return inputs,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXY(foldNo,folds,inputs,labels):\n",
    "    test_id       = list(folds[folds['fold']==foldNo].index)\n",
    "    train_id      = list(folds[folds['fold']!=foldNo].index)\n",
    "    X             = inputs[inputs.index.isin(train_id)]\n",
    "    X_val         = inputs[inputs.index.isin(test_id)]\n",
    "    y_label       = labels[labels.index.isin(train_id)]\n",
    "    y_label_test  = labels[labels.index.isin(test_id)]\n",
    "    y_lower       = y_label['min.log.lambda']\n",
    "    y_upper       = y_label['max.log.lambda']\n",
    "    y_lower_val   = y_label_test['min.log.lambda']\n",
    "    y_upper_val   = y_label_test['max.log.lambda']\n",
    "    res           = {}\n",
    "    res['X']         = X\n",
    "    res['X_val']     = X_val\n",
    "    res['y_lower']      = y_lower\n",
    "    res['y_lower_val']  = y_lower_val\n",
    "    res['y_upper']      = y_upper\n",
    "    res['y_upper_val']  = y_upper_val\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(X,X_val,y_lower,y_upper,y_lower_val,y_upper_val,params,num_round,distributionCol):\n",
    "    \n",
    "    res    = {}\n",
    "    dtrain = xgb.DMatrix(X)\n",
    "    dtrain.set_float_info(\"label_lower_bound\",y_lower.values)\n",
    "    dtrain.set_float_info(\"label_upper_bound\",y_upper.values)\n",
    "\n",
    "    dtest  = xgb.DMatrix(X_val)\n",
    "    dtest.set_float_info(\"label_lower_bound\",y_lower_val.values)\n",
    "    dtest.set_float_info(\"label_upper_bound\",y_upper_val.values)\n",
    "    \n",
    "    bst    = xgb.train(params,dtrain,num_boost_round=num_round,evals=[(dtrain,\"train\"),(dtest,\"test\")],evals_result=res,verbose_eval=False)\n",
    "    min_val_error = round(np.min(res['test'][distributionCol]),4)\n",
    "    return(min_val_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(distribution,trial):\n",
    "    \n",
    "    SEED         = 1\n",
    "    Kfolds       = KFold(n_splits=5,shuffle=True,random_state=SEED)\n",
    "    num_round    = 5000\n",
    "    res          = 0\n",
    "    \n",
    "    eta              = trial.suggest_discrete_uniform('eta',0.001,1.001,0.1)\n",
    "    max_depth        = trial.suggest_discrete_uniform('max_depth',2, 10,2)\n",
    "    \n",
    "#     min_child_weight = trial.suggest_discrete_uniform('min_child_weight',0.1,100.1,10)\n",
    "#     reg_alpha        = trial.suggest_loguniform('reg_alpha',0.0001,100)\n",
    "#     reg_lambda       = trial.suggest_loguniform('reg_lambda',0.0001,100)\n",
    "\n",
    "    min_child_weight = 0.1\n",
    "    reg_alpha        = 0.005\n",
    "    reg_lambda       = 0.5\n",
    "    \n",
    "    if distribution in ['normal','logistic']:\n",
    "        sigma  = 1\n",
    "    else:\n",
    "        sigma  = 10\n",
    "    \n",
    "    distribution_sigma = distribution+ ',' + str(sigma)\n",
    "    eval_metric     = 'aft-nloglik@'+distribution_sigma\n",
    "    base_score      = 0.5\n",
    "    \n",
    "    params   = {\n",
    "                'eta':eta,\n",
    "                'max_depth':int(max_depth),\n",
    "                'min_child_weight':min_child_weight,\n",
    "                'subsample':0.7,\n",
    "                'reg_alpha':reg_alpha,\n",
    "                'reg_lambda':reg_lambda,\n",
    "                'aft_noise_distribution' : distribution, \n",
    "                'aft_sigma': sigma,\n",
    "                'eval_metric':eval_metric,\n",
    "                'base_score':base_score,\n",
    "                'objective':\"aft:survival\",\n",
    "                'verbosity': 0\n",
    "                }\n",
    "    \n",
    "    for fold_, (trn_idx, val_idx) in enumerate(Kfolds.split(X, y_lower,y_upper)):\n",
    "        tr_x, tr_y_lower,tr_y_upper = X.iloc[trn_idx,:],y_lower.iloc[trn_idx],y_upper.iloc[trn_idx]\n",
    "        vl_x, vl_y_lower,vl_y_upper = X.iloc[val_idx,:], y_lower.iloc[val_idx],y_upper.iloc[val_idx]\n",
    "        res = res + trainModel(tr_x,vl_x,tr_y_lower,tr_y_upper,vl_y_lower,vl_y_upper,params,num_round,distribution_sigma)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_iter(eta,max_depth,min_child_weight,reg_alpha,reg_lambda,sigma,distribution): \n",
    "    SEED          = 1\n",
    "    Kfolds        = KFold(n_splits=5,shuffle=True,random_state=SEED)\n",
    "    num_round     = 5000\n",
    "    # Discrete-uniform parameter\n",
    "    distributionCol = distribution+ ',' + str(sigma)\n",
    "    eval_metric     = 'aft-nloglik@'+distributionCol\n",
    "    base_score      = 0.5\n",
    "    \n",
    "    params   = {\n",
    "                'eta':eta,\n",
    "                'max_depth':int(max_depth),\n",
    "                'min_child_weight':min_child_weight,\n",
    "                'subsample':0.7,\n",
    "                'reg_alpha':reg_alpha,\n",
    "                'reg_lambda':reg_lambda,\n",
    "                'aft_noise_distribution' : distribution, \n",
    "                'aft_sigma': sigma,\n",
    "                'eval_metric':eval_metric,\n",
    "                'base_score':base_score,\n",
    "                'objective':\"aft:survival\",\n",
    "                'verbosity': 0\n",
    "                }\n",
    "\n",
    "    res_data = pd.DataFrame()\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(Kfolds.split(X, y_lower,y_upper)):\n",
    "        tr_x, tr_y_lower,tr_y_upper = X.iloc[trn_idx,:],y_lower.iloc[trn_idx],y_upper.iloc[trn_idx]\n",
    "        vl_x, vl_y_lower,vl_y_upper = X.iloc[val_idx,:], y_lower.iloc[val_idx],y_upper.iloc[val_idx]\n",
    "        res_data[fold_] = trainModelIter(tr_x,vl_x,tr_y_lower,tr_y_upper,vl_y_lower,vl_y_upper,params,num_round,distributionCol)\n",
    "    res_data['total'] = res_data.sum(axis=1)\n",
    "    res = {}\n",
    "    num_round = res_data.idxmin(axis=0, skipna=True)['total']\n",
    "    res['num_round'] = num_round\n",
    "    res['min_val_error'] = min(res_data['total'])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name_domain = ['ATAC_JV_adipose','CTCF_TDH_ENCODE','H3K27ac-H3K4me3_TDHAM_BP','H3K27ac_TDH_some','H3K36me3_AM_immune']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data      = data_import(data_name_domain[0])\n",
    "data_name = data_name_domain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = data['inputs']\n",
    "labels = data['labels']\n",
    "folds  = data['folds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs,labels = data_massage(inputs,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "global X\n",
    "global X_val\n",
    "global y_lower\n",
    "global y_upper\n",
    "global y_upper_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_time = {}\n",
    "error    = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-26 05:11:30,440] A new study created with name: no-name-bb4056b5-b97c-4853-b2ab-2d5c0761ee0c\n",
      "[I 2019-12-26 05:11:42,970] Finished trial#0 resulted in value: inf. Current best value is inf with parameters: {'eta': 0.401, 'max_depth': 8.0}.\n",
      "[I 2019-12-26 05:11:52,485] Finished trial#1 resulted in value: 1.8709. Current best value is 1.8709 with parameters: {'eta': 0.001, 'max_depth': 4.0}.\n",
      "[I 2019-12-26 05:11:59,088] Finished trial#2 resulted in value: 4.1225. Current best value is 1.8709 with parameters: {'eta': 0.001, 'max_depth': 4.0}.\n",
      "[I 2019-12-26 05:12:09,470] Finished trial#3 resulted in value: 4.505. Current best value is 1.8709 with parameters: {'eta': 0.001, 'max_depth': 4.0}.\n",
      "[I 2019-12-26 05:12:20,631] Finished trial#4 resulted in value: inf. Current best value is 1.8709 with parameters: {'eta': 0.001, 'max_depth': 4.0}.\n",
      "[I 2019-12-26 05:12:31,676] Finished trial#5 resulted in value: inf. Current best value is 1.8709 with parameters: {'eta': 0.001, 'max_depth': 4.0}.\n",
      "[I 2019-12-26 05:12:48,080] Finished trial#6 resulted in value: inf. Current best value is 1.8709 with parameters: {'eta': 0.001, 'max_depth': 4.0}.\n",
      "[I 2019-12-26 05:13:03,117] Finished trial#7 resulted in value: 1.4474. Current best value is 1.4474 with parameters: {'eta': 0.001, 'max_depth': 8.0}.\n",
      "[I 2019-12-26 05:13:13,680] Finished trial#8 resulted in value: inf. Current best value is 1.4474 with parameters: {'eta': 0.001, 'max_depth': 8.0}.\n",
      "[I 2019-12-26 05:13:20,311] Finished trial#9 resulted in value: 5.055899999999999. Current best value is 1.4474 with parameters: {'eta': 0.001, 'max_depth': 8.0}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 logistic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-26 05:13:20,386] A new study created with name: no-name-5bdfafc9-77a7-43a8-a656-cfc4f8113532\n",
      "[I 2019-12-26 05:13:25,080] Finished trial#0 resulted in value: 498.77290000000005. Current best value is 498.77290000000005 with parameters: {'eta': 0.401, 'max_depth': 8.0}.\n",
      "[I 2019-12-26 05:13:35,208] Finished trial#1 resulted in value: 2.4814000000000003. Current best value is 2.4814000000000003 with parameters: {'eta': 0.001, 'max_depth': 4.0}.\n",
      "[I 2019-12-26 05:13:41,895] Finished trial#2 resulted in value: 3.2241999999999997. Current best value is 2.4814000000000003 with parameters: {'eta': 0.001, 'max_depth': 4.0}.\n",
      "[I 2019-12-26 05:13:46,568] Finished trial#3 resulted in value: 222.75099999999998. Current best value is 2.4814000000000003 with parameters: {'eta': 0.001, 'max_depth': 4.0}.\n",
      "[I 2019-12-26 05:13:51,200] Finished trial#4 resulted in value: 510.0426999999999. Current best value is 2.4814000000000003 with parameters: {'eta': 0.001, 'max_depth': 4.0}.\n",
      "[I 2019-12-26 05:13:55,839] Finished trial#5 resulted in value: 489.0973. Current best value is 2.4814000000000003 with parameters: {'eta': 0.001, 'max_depth': 4.0}.\n",
      "[I 2019-12-26 05:14:00,402] Finished trial#6 resulted in value: 230.95029999999997. Current best value is 2.4814000000000003 with parameters: {'eta': 0.001, 'max_depth': 4.0}.\n",
      "[I 2019-12-26 05:14:18,179] Finished trial#7 resulted in value: 2.8419000000000003. Current best value is 2.4814000000000003 with parameters: {'eta': 0.001, 'max_depth': 4.0}.\n",
      "[I 2019-12-26 05:14:22,780] Finished trial#8 resulted in value: 499.4662. Current best value is 2.4814000000000003 with parameters: {'eta': 0.001, 'max_depth': 4.0}.\n",
      "[W 2019-12-26 05:14:29,435] Setting status of trial#9 as TrialState.FAIL because the objective function returned nan.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 extreme\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-26 05:14:29,522] A new study created with name: no-name-69a3836b-1e3f-44d5-8166-2bfe284ca29c\n",
      "[I 2019-12-26 05:14:38,907] Finished trial#0 resulted in value: 10.8766. Current best value is 10.8766 with parameters: {'eta': 0.401, 'max_depth': 8.0}.\n",
      "[I 2019-12-26 05:14:45,255] Finished trial#1 resulted in value: 10.775799999999998. Current best value is 10.775799999999998 with parameters: {'eta': 0.001, 'max_depth': 4.0}.\n",
      "[I 2019-12-26 05:14:51,880] Finished trial#2 resulted in value: 10.4677. Current best value is 10.4677 with parameters: {'eta': 0.101, 'max_depth': 2.0}.\n",
      "[I 2019-12-26 05:15:01,338] Finished trial#3 resulted in value: 10.899700000000001. Current best value is 10.4677 with parameters: {'eta': 0.101, 'max_depth': 2.0}.\n",
      "[I 2019-12-26 05:15:10,263] Finished trial#4 resulted in value: 10.9832. Current best value is 10.4677 with parameters: {'eta': 0.101, 'max_depth': 2.0}.\n",
      "[I 2019-12-26 05:15:18,761] Finished trial#5 resulted in value: 11.350000000000001. Current best value is 10.4677 with parameters: {'eta': 0.101, 'max_depth': 2.0}.\n",
      "[I 2019-12-26 05:15:29,417] Finished trial#6 resulted in value: 11.043299999999999. Current best value is 10.4677 with parameters: {'eta': 0.101, 'max_depth': 2.0}.\n",
      "[I 2019-12-26 05:15:36,167] Finished trial#7 resulted in value: 10.6516. Current best value is 10.4677 with parameters: {'eta': 0.101, 'max_depth': 2.0}.\n",
      "[I 2019-12-26 05:15:45,037] Finished trial#8 resulted in value: 11.2769. Current best value is 10.4677 with parameters: {'eta': 0.101, 'max_depth': 2.0}.\n",
      "[I 2019-12-26 05:15:51,698] Finished trial#9 resulted in value: 10.8728. Current best value is 10.4677 with parameters: {'eta': 0.101, 'max_depth': 2.0}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-26 05:15:51,777] A new study created with name: no-name-85d555fe-9146-4981-90c6-176bfcb5af64\n",
      "[I 2019-12-26 05:16:01,625] Finished trial#0 resulted in value: inf. Current best value is inf with parameters: {'eta': 0.401, 'max_depth': 8.0}.\n",
      "[I 2019-12-26 05:16:11,365] Finished trial#1 resulted in value: 1.2792. Current best value is 1.2792 with parameters: {'eta': 0.001, 'max_depth': 4.0}.\n",
      "[I 2019-12-26 05:16:17,893] Finished trial#2 resulted in value: 12.217100000000002. Current best value is 1.2792 with parameters: {'eta': 0.001, 'max_depth': 4.0}.\n",
      "[I 2019-12-26 05:16:27,670] Finished trial#3 resulted in value: 16.4854. Current best value is 1.2792 with parameters: {'eta': 0.001, 'max_depth': 4.0}.\n",
      "[I 2019-12-26 05:16:37,083] Finished trial#4 resulted in value: inf. Current best value is 1.2792 with parameters: {'eta': 0.001, 'max_depth': 4.0}.\n",
      "[I 2019-12-26 05:16:48,815] Finished trial#5 resulted in value: inf. Current best value is 1.2792 with parameters: {'eta': 0.001, 'max_depth': 4.0}.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-2beff8948cd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mdatabase_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sqlite:///'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdistribution\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".db\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatabase_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdistribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mtrial\u001b[0m         \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mend\u001b[0m            \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                 self._optimize_sequential(func, n_trials, timeout, catch, callbacks,\n\u001b[0;32m--> 261\u001b[0;31m                                           gc_after_trial)\n\u001b[0m\u001b[1;32m    262\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m                 self._optimize_parallel(func, n_trials, timeout, n_jobs, catch, callbacks,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[1;32m    441\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     def _optimize_parallel(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[0;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;31m# type: (...) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             message = 'Setting status of trial#{} as {}. {}'.format(trial_number,\n",
      "\u001b[0;32m<ipython-input-6-0a22f99bf45e>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(distribution, trial)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mtr_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_y_lower\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtr_y_upper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_lower\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_upper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mvl_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvl_y_lower\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvl_y_upper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_lower\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_upper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvl_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtr_y_lower\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtr_y_upper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvl_y_lower\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvl_y_upper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdistribution_sigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-bc10319cf935>\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m(X, X_val, y_lower, y_upper, y_lower_val, y_upper_val, params, num_round, distributionCol)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_float_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"label_upper_bound\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_upper_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mbst\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mmin_val_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdistributionCol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_val_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/xgboost/python-package/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    217\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/xgboost/python-package/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/xgboost/python-package/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1182\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for fold in np.unique(folds['fold'].values):\n",
    "    \n",
    "    start        = time.time()\n",
    "    res          = getXY(fold,folds,inputs,labels)\n",
    "    X            = res['X']        \n",
    "    X_val        = res['X_val']\n",
    "    y_lower      = res['y_lower']\n",
    "    y_lower_val  = res['y_lower_val']\n",
    "    y_upper      = res['y_upper']\n",
    "    y_upper_val  = res['y_upper_val']\n",
    "    \n",
    "    for distribution in ['normal','logistic','extreme']:\n",
    "        print(fold,distribution)\n",
    "        sampler = TPESampler(seed=1)  # Make the sampler behave in a deterministic way.\n",
    "        database_name = 'sqlite:///'+str(fold)+\"_\"+distribution+\".db\"\n",
    "        study = optuna.create_study(sampler=sampler,storage=database_name)\n",
    "        study.optimize(functools.partial(objective,distribution), n_trials=100)\n",
    "        trial         = study.best_trial\n",
    "    end            = time.time()\n",
    "    time_taken     = end - start\n",
    "    run_time[fold] = time_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_time1 ={}\n",
    "for key in run_time.keys():\n",
    "    run_time1[str(key)] = run_time[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_filename = \"../../../../../result/\"+data_name+\"/xgboost/run_time_2_param_tuning1.json\"\n",
    "with open(json_filename, \"w\") as write_file:\n",
    "    json.dump(run_time1, write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModelIter(X,X_val,y_lower,y_upper,y_lower_val,y_upper_val,params,num_round,distributionCol):\n",
    "    \n",
    "    res    = {}\n",
    "    dtrain = xgb.DMatrix(X)\n",
    "    dtrain.set_float_info(\"label_lower_bound\",y_lower)\n",
    "    dtrain.set_float_info(\"label_upper_bound\",y_upper)\n",
    "\n",
    "    dtest  = xgb.DMatrix(X_val)\n",
    "    dtest.set_float_info(\"label_lower_bound\",y_lower_val)\n",
    "    dtest.set_float_info(\"label_upper_bound\",y_upper_val)\n",
    "\n",
    "    bst    = xgb.train(params,dtrain,num_boost_round=num_round,evals=[(dtrain,\"train\"),(dtest,\"test\")],evals_result=res,verbose_eval=False)\n",
    "    val_error = res['test'][distributionCol]\n",
    "    \n",
    "    return(val_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_time2 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for fold in range(2,3):\n",
    "for fold in np.unique(folds['fold'].values):\n",
    "    start_time   = time.time()\n",
    "    res = getXY(fold,folds,inputs,labels)\n",
    "    X            = res['X']        \n",
    "    X_val        = res['X_val']\n",
    "    y_lower      = res['y_lower']\n",
    "    y_lower_val  = res['y_lower_val']\n",
    "    y_upper      = res['y_upper']\n",
    "    y_upper_val  = res['y_upper_val']\n",
    "    \n",
    "    for distribution in ['normal','logistic','extreme']:\n",
    "        json_filename = \"../../../../../result/\"+data_name+\"/xgboost/fold\"+str(fold)+'_'+distribution+'_param_2.json'\n",
    "        with open(json_filename, errors='ignore') as json_data:\n",
    "            json_fold = json.load(json_data, strict=False)\n",
    "        eta = json_fold['eta']\n",
    "        max_depth = json_fold['max_depth']\n",
    "        min_child_weight = 0.1\n",
    "        reg_alpha        = 0.005\n",
    "        reg_lambda       = 0.5\n",
    "        sigma= 1\n",
    "        res      = best_iter(eta,max_depth,min_child_weight,reg_alpha,reg_lambda,sigma,distribution)\n",
    "        new_json = {}\n",
    "        new_json['eta'] = eta\n",
    "        new_json['max_depth'] = max_depth\n",
    "        new_json['min_child_weight'] = min_child_weight\n",
    "        new_json['reg_alpha']     = reg_alpha\n",
    "        new_json['reg_lambda']    = reg_lambda\n",
    "        new_json['sigma']         = sigma\n",
    "        new_json['distribution']  = distribution\n",
    "        new_json['num_round']     = int(res['num_round'])\n",
    "        if res['min_val_error'] == float('inf'):\n",
    "            res['min_val_error'] = 10**8\n",
    "        new_json['min_val_error'] = res['min_val_error']\n",
    "        json_filename = \"../../../../../result/\"+data_name+\"/xgboost/fold_new\"+str(fold)+'_'+distribution+'_param_2.json'\n",
    "        with open(json_filename, \"w\") as write_file:\n",
    "             json.dump(new_json, write_file)\n",
    "    end_time        = time.time()\n",
    "    time_taken      = end_time - start_time\n",
    "    run_time2[fold] = time_taken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing best hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for fold in range(2,3):\n",
    "for fold in np.unique(folds['fold'].values):\n",
    "    fold_data = pd.DataFrame()\n",
    "    for distribution in ['normal','logistic','extreme']:\n",
    "        json_filename = \"../../../../result/\"+data_name+\"/xgboost/fold_new\"+str(fold)+'_'+distribution+'_param_2.json'\n",
    "        with open(json_filename, errors='ignore') as json_data:\n",
    "            json_fold = json.load(json_data, strict=False)\n",
    "        dist_data = pd.DataFrame.from_dict(json_fold,orient='index',columns=[distribution])\n",
    "        fold_data = pd.concat([fold_data,dist_data],axis=1)\n",
    "    fold_data = fold_data.transpose()\n",
    "    fold_data['min_val_error'] = fold_data['min_val_error'].astype('float')\n",
    "    best_dis   = fold_data['min_val_error'].idxmin()\n",
    "    best_param = fold_data.loc[best_dis]\n",
    "    json_filename = \"../../../../result/\"+data_name+\"/xgboost/fold_new\"+str(fold)+'_dis'+'_param_2.json'\n",
    "    best_param = best_param.to_dict()\n",
    "    with open(json_filename, \"w\") as write_file:\n",
    "        json.dump(best_param, write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_time3 ={}\n",
    "for key in run_time2.keys():\n",
    "    run_time3[str(key)] = run_time2[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_filename = \"../../../../../result/\"+data_name+\"/xgboost/run_time_2_param_tuning2.json\"\n",
    "with open(json_filename, \"w\") as write_file:\n",
    "    json.dump(run_time3, write_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
