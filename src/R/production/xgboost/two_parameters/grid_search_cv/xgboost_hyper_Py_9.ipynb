{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas  as pd\n",
    "import numpy   as np\n",
    "from   sklearn.model_selection import KFold\n",
    "import optuna\n",
    "import time\n",
    "import json\n",
    "from   optuna.samplers import TPESampler\n",
    "import functools\n",
    "import itertools\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigma Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Data Name                |Normal|Logistic| Extreme | \n",
    "|--------------------------|------|--------|---------|\n",
    "|ATAC_JV_adipose           | 1    | 1      |    10   |\n",
    "|CTCF_TDH_ENCODE           | 1    | 1      |    10   |\n",
    "|H3K27ac-H3K4me3_TDHAM_BP  | 1    | 1      |    10   |\n",
    "|H3K27ac_TDH_some          | 1    | 1      |    10   |\n",
    "|H3K36me3_AM_immune        | 1    | 1      |    10   |\n",
    "|H3K27me3_RL_cancer        | 10   | 1      |    10   |\n",
    "|H3K27me3_TDH_some         | 15   | 1      |    10   |\n",
    "|H3K36me3_TDH_ENCODE       | 1    | 1      |    10   |\n",
    "|H3K36me3_TDH_immune       | 10   | 1      |    10   |\n",
    "|H3K36me3_TDH_other        | 10   | 1      |    10   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_import(data_name):\n",
    "    filename = '../../../../../../data/'+data_name+'/'\n",
    "    inputFileName = filename+'inputs.csv'\n",
    "    labelFileName = filename+'outputs.csv'\n",
    "    foldsFileName = filename+'cv/equal_labels/folds.csv'\n",
    "    inputs        = pd.read_csv(inputFileName,index_col='sequenceID')\n",
    "    labels        = pd.read_csv(labelFileName,index_col='sequenceID')\n",
    "    folds         = pd.read_csv(foldsFileName,index_col='sequenceID')\n",
    "    res           = {}\n",
    "    res['inputs'] = inputs\n",
    "    res['labels'] = labels\n",
    "    res['folds']  = folds\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_massage(inputs,labels):\n",
    "    inputs.replace([-float('inf'),float('inf')],np.nan,inplace=True)\n",
    "    missingCols = inputs.isnull().sum()\n",
    "    missingCols = list(missingCols[missingCols>0].index)\n",
    "    inputs.drop(missingCols,axis=1,inplace=True)\n",
    "    varCols     = inputs.apply(lambda x: np.var(x))\n",
    "    zeroVarCols = list(varCols[varCols==0].index)\n",
    "    inputs.drop(zeroVarCols,axis=1,inplace=True)\n",
    "    labels['min.log.lambda'] = labels['min.log.lambda'].apply(lambda x: np.exp(x))\n",
    "    labels['max.log.lambda'] = labels['max.log.lambda'].apply(lambda x: np.exp(x))\n",
    "    return inputs,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXY(foldNo,folds,inputs,labels):\n",
    "    test_id       = list(folds[folds['fold']==foldNo].index)\n",
    "    train_id      = list(folds[folds['fold']!=foldNo].index)\n",
    "    X             = inputs[inputs.index.isin(train_id)]\n",
    "    X_val         = inputs[inputs.index.isin(test_id)]\n",
    "    y_label       = labels[labels.index.isin(train_id)]\n",
    "    y_label_test  = labels[labels.index.isin(test_id)]\n",
    "    y_lower       = y_label['min.log.lambda']\n",
    "    y_upper       = y_label['max.log.lambda']\n",
    "    y_lower_val   = y_label_test['min.log.lambda']\n",
    "    y_upper_val   = y_label_test['max.log.lambda']\n",
    "    res           = {}\n",
    "    res['X']         = X\n",
    "    res['X_val']     = X_val\n",
    "    res['y_lower']      = y_lower\n",
    "    res['y_lower_val']  = y_lower_val\n",
    "    res['y_upper']      = y_upper\n",
    "    res['y_upper_val']  = y_upper_val\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(X,X_val,y_lower,y_upper,y_lower_val,y_upper_val,params,num_round,distributionCol):\n",
    "    \n",
    "    res    = {}\n",
    "    dtrain = xgb.DMatrix(X)\n",
    "    dtrain.set_float_info(\"label_lower_bound\",y_lower.values)\n",
    "    dtrain.set_float_info(\"label_upper_bound\",y_upper.values)\n",
    "\n",
    "    dtest  = xgb.DMatrix(X_val)\n",
    "    dtest.set_float_info(\"label_lower_bound\",y_lower_val.values)\n",
    "    dtest.set_float_info(\"label_upper_bound\",y_upper_val.values)\n",
    "    \n",
    "    bst    = xgb.train(params,dtrain,num_boost_round=num_round,evals=[(dtrain,\"train\"),(dtest,\"test\")],evals_result=res,verbose_eval=False)\n",
    "    min_val_error = round(np.min(res['test'][distributionCol]),4)\n",
    "    return(min_val_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_cv_step(X, y_lower, y_upper, Kfolds, params, num_round, distribution_sigma):\n",
    "    res = 0\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(Kfolds.split(X, y_lower,y_upper)):\n",
    "        tr_x, tr_y_lower,tr_y_upper = X.iloc[trn_idx,:],y_lower.iloc[trn_idx],y_upper.iloc[trn_idx]\n",
    "        vl_x, vl_y_lower,vl_y_upper = X.iloc[val_idx,:], y_lower.iloc[val_idx],y_upper.iloc[val_idx]\n",
    "        res = res + trainModel(tr_x,vl_x,tr_y_lower,tr_y_upper,vl_y_lower,vl_y_upper,params,num_round,distribution_sigma)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "global min_child_weight \n",
    "global reg_alpha\n",
    "global reg_lambda\n",
    "global subsample\n",
    "global num_round\n",
    "global base_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_child_weight = 0.1\n",
    "reg_alpha        = 0.005\n",
    "reg_lambda       = 0.5\n",
    "subsample        = 0.7\n",
    "num_round        = 5000\n",
    "base_score       = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_cv(X, y_lower, y_upper, distribution, sigma):\n",
    "    \n",
    "    SEED         = 1\n",
    "    Kfolds       = KFold(n_splits=5,shuffle=True,random_state=SEED)\n",
    "\n",
    "    res          = 0\n",
    "    eta_range        = list(np.logspace(np.log10(0.001), np.log10(1), base = 10, num = 10))\n",
    "    max_depth_range  = np.arange(2,10,2)\n",
    "    \n",
    "    \n",
    "    distribution_sigma = distribution+ ',' + str(sigma)\n",
    "    eval_metric  = 'aft-nloglik@'+distribution_sigma\n",
    "\n",
    "    error_results = []\n",
    "    etas          = []\n",
    "    max_depths    = []\n",
    "    \n",
    "    for eta in eta_range:\n",
    "        for max_depth in max_depth_range:\n",
    "            params   = {\n",
    "                        'eta':eta,\n",
    "                        'max_depth':int(max_depth),\n",
    "                        'min_child_weight':min_child_weight,\n",
    "                        'subsample':subsample,\n",
    "                        'reg_alpha':reg_alpha,\n",
    "                        'reg_lambda':reg_lambda,\n",
    "                        'aft_noise_distribution' : distribution, \n",
    "                        'aft_sigma': sigma,\n",
    "                        'eval_metric':eval_metric,\n",
    "                        'base_score':base_score,\n",
    "                        'objective':\"aft:survival\",\n",
    "                        'verbosity': 0\n",
    "                        }\n",
    "            error_result = grid_search_cv_step(X, y_lower, y_upper, Kfolds, params, num_round, distribution_sigma)\n",
    "            error_results.append(error_result)\n",
    "            etas.append(eta)\n",
    "            max_depths.append(max_depth)\n",
    "\n",
    "    return etas,max_depths,error_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_iter(eta,max_depth,min_child_weight,reg_alpha,reg_lambda,sigma,distribution, X, y_lower,y_upper): \n",
    "    \n",
    "    SEED          = 1\n",
    "    Kfolds        = KFold(n_splits=5,shuffle=True,random_state=SEED)\n",
    "    num_round     = 5000\n",
    "    # Discrete-uniform parameter\n",
    "    distributionCol = distribution+ ',' + str(sigma)\n",
    "    eval_metric     = 'aft-nloglik@'+distributionCol\n",
    "    base_score      = 0.5\n",
    "    \n",
    "    params   = {\n",
    "                'eta':eta,\n",
    "                'max_depth':int(max_depth),\n",
    "                'min_child_weight':min_child_weight,\n",
    "                'subsample':0.7,\n",
    "                'reg_alpha':reg_alpha,\n",
    "                'reg_lambda':reg_lambda,\n",
    "                'aft_noise_distribution' : distribution, \n",
    "                'aft_sigma': sigma,\n",
    "                'eval_metric':eval_metric,\n",
    "                'base_score':base_score,\n",
    "                'objective':\"aft:survival\",\n",
    "                'verbosity': 0\n",
    "                }\n",
    "\n",
    "    res_data = pd.DataFrame()\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(Kfolds.split(X, y_lower,y_upper)):\n",
    "        tr_x, tr_y_lower,tr_y_upper = X.iloc[trn_idx,:],y_lower.iloc[trn_idx],y_upper.iloc[trn_idx]\n",
    "        vl_x, vl_y_lower,vl_y_upper = X.iloc[val_idx,:], y_lower.iloc[val_idx],y_upper.iloc[val_idx]\n",
    "        res_data[fold_] = trainModelIter(tr_x,vl_x,tr_y_lower,tr_y_upper,vl_y_lower,vl_y_upper,params,num_round,distributionCol)\n",
    "    res_data['total'] = res_data.sum(axis=1)\n",
    "    res = {}\n",
    "    num_round = res_data.idxmin(axis=0, skipna=True)['total']\n",
    "    res['num_round'] = num_round\n",
    "    res['min_val_error'] = min(res_data['total'])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_name):\n",
    "    data   = data_import(data_name)\n",
    "    inputs = data['inputs']\n",
    "    labels = data['labels']\n",
    "    folds  = data['folds']\n",
    "    inputs,labels = data_massage(inputs,labels)\n",
    "    return folds,inputs,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_param(etas,max_depths,error_results):\n",
    "    para_result    = pd.DataFrame()\n",
    "    para_result['etas']          = etas\n",
    "    para_result['max_depths']    = max_depths\n",
    "    para_result['error_results'] = error_results\n",
    "    min_index                    = para_result['error_results'].idxmin()\n",
    "    best_eta = para_result.loc[min_index,'etas']\n",
    "    best_max_depth = para_result.loc[min_index,'max_depths']\n",
    "    return best_eta,best_max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_parameters(data_name,sigmas):\n",
    "    folds,inputs,labels = get_data(data_name)\n",
    "    run_time = {}\n",
    "    for fold in np.unique(folds['fold'].values):\n",
    "        start          = time.time()\n",
    "        res          = getXY(fold,folds,inputs,labels)\n",
    "        X            = res['X']       \n",
    "        X_val        = res['X_val']\n",
    "        y_lower      = res['y_lower']\n",
    "        y_lower_val  = res['y_lower_val']\n",
    "        y_upper      = res['y_upper']\n",
    "        y_upper_val  = res['y_upper_val']\n",
    "        for distribution in ['normal','logistic','extreme']:\n",
    "            if distribution=='normal':\n",
    "                sigma = sigmas['normal']\n",
    "            elif distribution=='logistic':\n",
    "                sigma = sigmas['logistic']\n",
    "            elif distribution=='extreme':\n",
    "                sigma = sigmas['extreme']\n",
    "            \n",
    "            etas,max_depths,error_results = grid_search_cv(X, y_lower, y_upper, distribution,sigma)\n",
    "            best_eta,best_max_depth = get_best_param(etas,max_depths,error_results)\n",
    "            end            = time.time()\n",
    "            time_taken     = end - start\n",
    "            print(time_taken)\n",
    "            key           = str(fold)+\"_\"+distribution\n",
    "            run_time[key] = time_taken\n",
    "            best_param = {}\n",
    "            best_param['eta']       = best_eta\n",
    "            best_param['max_depth'] = int(best_max_depth)\n",
    "            best_param['min_child_weight'] = min_child_weight\n",
    "            best_param['reg_alpha']        = reg_alpha\n",
    "            best_param['reg_lambda']       = reg_lambda\n",
    "            best_param['sigma']            = sigma\n",
    "            best_param['distribution']     = distribution\n",
    "            best_param['num_round']        = num_round\n",
    "            json_filename = \"../../../../../../result/\"+data_name+\"/xgboost/fold\"+str(fold)+'_'+distribution+'_param_2_grid_search.json'\n",
    "            with open(json_filename, \"w\") as write_file:\n",
    "                 json.dump(best_param, write_file)\n",
    "    return run_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModelIter(X,X_val,y_lower,y_upper,y_lower_val,y_upper_val,params,num_round,distributionCol):\n",
    "    \n",
    "    res    = {}\n",
    "    dtrain = xgb.DMatrix(X)\n",
    "    dtrain.set_float_info(\"label_lower_bound\",y_lower)\n",
    "    dtrain.set_float_info(\"label_upper_bound\",y_upper)\n",
    "\n",
    "    dtest  = xgb.DMatrix(X_val)\n",
    "    dtest.set_float_info(\"label_lower_bound\",y_lower_val)\n",
    "    dtest.set_float_info(\"label_upper_bound\",y_upper_val)\n",
    "\n",
    "    bst       = xgb.train(params,dtrain,num_boost_round=num_round,evals=[(dtrain,\"train\"),(dtest,\"test\")],evals_result=res,verbose_eval=False)\n",
    "    val_error = res['test'][distributionCol]\n",
    "    \n",
    "    return(val_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_num_round(data_name,sigmas,run_time):\n",
    "    \n",
    "    folds,inputs,labels = get_data(data_name)\n",
    "    \n",
    "    for fold in np.unique(folds['fold'].values):\n",
    "        start_time          = time.time()\n",
    "        res          = getXY(fold,folds,inputs,labels)\n",
    "        X            = res['X']       \n",
    "        X_val        = res['X_val']\n",
    "        y_lower      = res['y_lower']\n",
    "        y_lower_val  = res['y_lower_val']\n",
    "        y_upper      = res['y_upper']\n",
    "        y_upper_val  = res['y_upper_val']\n",
    "        for distribution in ['normal','logistic','extreme']:\n",
    "            if distribution=='normal':\n",
    "                sigma = sigmas['normal']\n",
    "            elif distribution=='logistic':\n",
    "                sigma = sigmas['logistic']\n",
    "            elif distribution=='extreme':\n",
    "                sigma = sigmas['extreme']\n",
    "            \n",
    "            json_filename = \"../../../../../../result/\"+data_name+\"/xgboost/fold\"+str(fold)+'_'+distribution+'_param_2_grid_search.json'\n",
    "            with open(json_filename, errors='ignore') as json_data:\n",
    "                json_fold = json.load(json_data, strict=False)\n",
    "            eta = json_fold['eta']\n",
    "            max_depth = json_fold['max_depth']\n",
    "            res      = best_iter(eta,max_depth,min_child_weight,reg_alpha,reg_lambda,sigma,distribution,X, y_lower,y_upper)\n",
    "            res_param = {}\n",
    "            res_param['eta'] = eta\n",
    "            res_param['max_depth'] = max_depth\n",
    "            res_param['min_child_weight'] = min_child_weight\n",
    "            res_param['reg_alpha']     = reg_alpha\n",
    "            res_param['reg_lambda']    = reg_lambda\n",
    "            res_param['sigma']         = sigma\n",
    "            res_param['distribution']  = distribution\n",
    "            res_param['num_round']     = int(res['num_round'])\n",
    "            if res['min_val_error'] == float('inf'):\n",
    "                res['min_val_error'] = 10**8\n",
    "            res_param['min_val_error'] = res['min_val_error']\n",
    "            json_filename = \"../../../../../../result/\"+data_name+\"/xgboost/fold_new\"+str(fold)+'_'+distribution+'_param_2_grid_search.json'\n",
    "            with open(json_filename, \"w\") as write_file:\n",
    "                 json.dump(res_param, write_file)\n",
    "            end_time        = time.time()\n",
    "            time_taken      = end_time - start_time\n",
    "            key             = str(fold)+\"_\"+distribution\n",
    "            run_time[key] = run_time[key] + time_taken\n",
    "    return run_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name_domain = ['ATAC_JV_adipose','CTCF_TDH_ENCODE','H3K27ac-H3K4me3_TDHAM_BP',\n",
    "                    'H3K27ac_TDH_some','H3K36me3_AM_immune','H3K27me3_RL_cancer',\n",
    "                    'H3K27me3_TDH_some','H3K36me3_TDH_ENCODE','H3K36me3_TDH_immune','H3K36me3_TDH_other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = data_name_domain[9]\n",
    "sigmas    = {}\n",
    "sigmas['normal']   = 10\n",
    "sigmas['logistic'] = 1\n",
    "sigmas['extreme']  = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.839357614517212\n",
      "23.425172090530396\n",
      "35.38545370101929\n",
      "12.014249801635742\n",
      "23.808838605880737\n",
      "36.07618546485901\n",
      "13.030861616134644\n",
      "25.779943466186523\n",
      "39.11256289482117\n",
      "12.032529592514038\n",
      "23.752265214920044\n",
      "35.79760980606079\n"
     ]
    }
   ],
   "source": [
    "run_time = get_best_parameters(data_name,sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_time = get_best_num_round(data_name,sigmas,run_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_filename = \"../../../../../../result/\"+data_name+\"/xgboost/run_dis_time_2_param_grid_search.json\"\n",
    "with open(json_filename, \"w\") as write_file:\n",
    "    json.dump(run_time, write_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
