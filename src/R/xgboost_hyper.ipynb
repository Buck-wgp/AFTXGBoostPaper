{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caret)\n",
    "library(xgboost)\n",
    "#library(MlBayesOpt)\n",
    "library(Matrix)\n",
    "library(rBayesianOptimization)\n",
    "#https://gitlab.com/avinashbarnwal/elokaggle/blob/master/code/304_hyperparameter_optuna.ipynb\n",
    "#https://gitlab.com/avinashbarnwal/elokaggle/blob/master/code/302_LGBM_BO_hyperpara.ipynb\n",
    "#https://cran.r-project.org/web/packages/MlBayesOpt/vignettes/MlBayesOpt.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_import =function(dataname){\n",
    "  filename = paste('https://raw.githubusercontent.com/avinashbarnwal/GSOC-2019/master/AFT/test/data/neuroblastoma-data-master/data/',dataname,'/',sep=\"\")\n",
    "  inputFileName = paste(filename,'inputs.csv',sep=\"\")\n",
    "  labelFileName = paste(filename,'outputs.csv',sep=\"\")\n",
    "  foldsFileName = paste(filename,'cv/equal_labels/folds.csv',sep=\"\")\n",
    "  inputs        = read.table(inputFileName,sep=\",\",header=T,stringsAsFactors = F,row.names=1)\n",
    "  labels        = read.table(labelFileName,sep=\",\",header=T,stringsAsFactors = F,row.names=1)\n",
    "  folds         = read.table(foldsFileName,sep=\",\",header=T,stringsAsFactors = F,row.names=1)\n",
    "  res           = list()\n",
    "  res$inputs    = inputs\n",
    "  res$labels    = labels\n",
    "  res$folds     = folds\n",
    "  return(res)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_massage = function(inputs,labels){\n",
    "    rownamesInput = rownames(inputs)\n",
    "    inputs        = do.call(data.frame,lapply(inputs, function(x) replace(x, is.infinite(x),NA)))\n",
    "    naColumns     = colnames(inputs)[colSums(is.na(inputs))>0]\n",
    "    noVarCol      = getNonVarCols(inputs)\n",
    "    removeCols    = c(naColumns,noVarCol)\n",
    "    inputs        = inputs[ , !(colnames(inputs) %in% removeCols)]\n",
    "    rownames(inputs) = rownamesInput\n",
    "    labels$min.log.lambda = unlist(lapply(labels$min.log.lambda,exp))\n",
    "    labels$max.log.lambda = unlist(lapply(labels$max.log.lambda,exp))\n",
    "    res        = list()\n",
    "    res$inputs = inputs\n",
    "    res$labels = labels\n",
    "    return(res)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "getXY<-function(foldNo,folds,inputs,labels){\n",
    "    test.id       = rownames(subset(folds,fold==foldNo))\n",
    "    train.id      = rownames(subset(folds,fold!=foldNo))\n",
    "    X             = subset(inputs,rownames(inputs) %in% train.id)\n",
    "    X             = as.matrix(X)\n",
    "    X.val         = subset(inputs,rownames(inputs) %in% test.id)\n",
    "    X.val         = as.matrix(X.val)\n",
    "    y.label       = subset(labels,rownames(labels) %in% train.id)\n",
    "    y.label.test  = subset(labels,rownames(labels) %in% test.id)\n",
    "    y.lower       = as.matrix(y.label$min.log.lambda)\n",
    "    y.upper       = as.matrix(y.label$max.log.lambda)\n",
    "    y.lower.val   = as.matrix(y.label.test$min.log.lambda)\n",
    "    y.upper.val   = as.matrix(y.label.test$max.log.lambda)\n",
    "    res           = list()\n",
    "    res$X         = X\n",
    "    res$X.val     = X.val\n",
    "    res$y.lower      = y.lower\n",
    "    res$y.lower.val  = y.lower.val\n",
    "    res$y.upper      = y.upper\n",
    "    res$y.upper.val  = y.upper.val\n",
    "    return(res)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "getNonVarCols<-function(data){\n",
    "    var_columns    = apply(inputs,2,var)\n",
    "    resCol         = names(var_columns[var_columns==0.0])\n",
    "    return(resCol)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Parameters\n",
    "dataNameRange       = c('ATAC_JV_adipose','CTCF_TDH_ENCODE','H3K27ac-H3K4me3_TDHAM_BP','H3K27ac_TDH_some','H3K36me3_AM_immune')\n",
    "sigma_range         = c(1,2,5,10,100)\n",
    "distribution_range  = c('normal','logistic','extreme')\n",
    "learning_rate       = 0.1\n",
    "num_round           = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "getaccuracy=function(pred,y_lower,y_higher){\n",
    "    res = (pred>=y_lower & pred<=y_higher)\n",
    "    return(res)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "getParam = function(sigma,distribution,learning_rate){\n",
    "  eval_metric = paste(\"aft-nloglik@\",distribution,\",\",sigma,sep=\"\") \n",
    "  param       = list(learning_rate=learning_rate, aft_noise_distribution=distribution, \n",
    "                    nthread = 4, verbosity=0, aft_sigma= sigma,\n",
    "                    eval_metric  = eval_metric,\n",
    "                    objective  = \"aft:survival\")\n",
    "  return(param)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainModel = function(foldNo,X,X_val,y_lower,y_lower_val,y_upper,y_upper_val,param,num_round){\n",
    "  \n",
    "  dtrain = xgb.DMatrix(X)\n",
    "  setinfo(dtrain,'label_lower_bound', y_lower)\n",
    "  setinfo(dtrain,'label_upper_bound', y_upper)\n",
    "  \n",
    "  dtest = xgb.DMatrix(X_val)\n",
    "  setinfo(dtest,'label_lower_bound', y_lower_val)\n",
    "  setinfo(dtest,'label_upper_bound', y_upper_val)\n",
    "  \n",
    "  watchlist = list(eval = dtest, train = dtrain)\n",
    "  bst       = xgb.train(param, dtrain, num_round, watchlist,verbose = 0)\n",
    "\n",
    "  return(bst)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cv_bayes = function(max_depth, min_child_weight, subsample, subsample_freq, \n",
    "                        colsample_bytree, reg_alpha, reg_lambda, nrounds, \n",
    "                        learning_rate, min_data_in_leaf, sigma, \n",
    "                        distribution) {\n",
    "    \n",
    "    eval_metric = paste(\"aft-nloglik@\",distribution,\",\",sigma,sep=\"\") \n",
    "    cv = xgb.cv(params = list(booster = \"gbtree\",\n",
    "                              max_depth = max_depth,\n",
    "                              min_child_weight = min_child_weight,\n",
    "                              subsample = subsample,\n",
    "                              subsample_freq = subsample_freq,\n",
    "                              colsample_bytree = colsample_bytree,\n",
    "                              reg_alpha = reg_alpha,\n",
    "                              reg_lambda = reg_lambda,\n",
    "                              nrounds = nrounds,\n",
    "                              learning_rate = learning_rate,\n",
    "                              min_data_in_leaf = min_data_in_leaf,\n",
    "                              aft_sigma = sigma,\n",
    "                              aft_noise_distribution = distribution,\n",
    "                              objective = eval_metric,\n",
    "                              nthread = 4,\n",
    "                              eval_metric = eval_metric),\n",
    "               data = dtrain,\n",
    "               folds = cv_folds, prediction = TRUE, showsd = TRUE,\n",
    "               early_stopping_rounds = 5, maximize = TRUE, verbose = 0)\n",
    "    \n",
    "    print(cv$evaluation_log)\n",
    "#     Score = cv$evaluation_log$test_auc_mean[cv$best_iteration]\n",
    "    list(Pred = cv$pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " bounds = list(num_leaves = c(3L, 1000L),\n",
    "               max_depth =  c(1L, 50L),\n",
    "               min_child_weight =  c(1, 60), \n",
    "               subsample =  c(0.1, 1),\n",
    "               subsample_freq = c(1, 100), \n",
    "               colsample_bytree =  c(0.0001, 1),\n",
    "               reg_alpha=c(0.0001, 10),\n",
    "               reg_lambda = c(1, 40),\n",
    "               nrounds    = c(50, 2000),\n",
    "               learning_rate=  c(0.0001, 1),\n",
    "               min_data_in_leaf =c(1, 50),\n",
    "               sigma = c(1,100),\n",
    "               distribution = c('normal','logistic','extreme'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in {: task 1 failed - \"invalid arguments\"\n",
     "output_type": "error",
     "traceback": [
      "Error in {: task 1 failed - \"invalid arguments\"\nTraceback:\n",
      "1. BayesianOptimization(xgb_cv_bayes, bounds = bounds, init_grid_dt = NULL, \n .     init_points = 10, n_iter = 20, acq = \"ucb\", kappa = 2.576, \n .     eps = 0, verbose = TRUE)",
      "2. Matrix_runif(n = init_points, lower = DT_bounds[, Lower], upper = DT_bounds[, \n .     Upper]) %>% data.table(.) %T>% setnames(., old = names(.), \n .     new = DT_bounds[, Parameter]) %T>% {\n .     if (any(DT_bounds[, Type] == \"integer\")) {\n .         set(., j = DT_bounds[Type == \"integer\", Parameter], value = round(extract(., \n .             j = DT_bounds[Type == \"integer\", Parameter], with = FALSE)))\n .     }\n .     else {\n .         .\n .     }\n . } %T>% extract(., j = `:=`(Value, -Inf))",
      "3. eval(lhs, parent, parent)",
      "4. eval(lhs, parent, parent)",
      "5. Matrix_runif(n = init_points, lower = DT_bounds[, Lower], upper = DT_bounds[, \n .     Upper])",
      "6. foreach(i = seq_along(lower), .combine = \"cbind\") %do% {\n .     runif(n, min = lower[i], max = upper[i]) %>% pmin(., upper[i] - \n .         sqrt(.Machine$double.eps)) %>% pmax(., lower[i] + sqrt(.Machine$double.eps))\n . } %>% matrix(., nrow = n, ncol = length(lower))",
      "7. eval(lhs, parent, parent)",
      "8. eval(lhs, parent, parent)",
      "9. foreach(i = seq_along(lower), .combine = \"cbind\") %do% {\n .     runif(n, min = lower[i], max = upper[i]) %>% pmin(., upper[i] - \n .         sqrt(.Machine$double.eps)) %>% pmax(., lower[i] + sqrt(.Machine$double.eps))\n . }",
      "10. e$fun(obj, substitute(ex), parent.frame(), e$data)"
     ]
    }
   ],
   "source": [
    "for(i in 1:1){\n",
    "    \n",
    "    res                 = data_import(dataNameRange[1])\n",
    "    inputs              = res$inputs\n",
    "    labels              = res$labels\n",
    "    folds               = res$folds\n",
    "    resDataMassage      = data_massage(inputs,labels)\n",
    "    inputs              = resDataMassage$inputs\n",
    "    labels              = resDataMassage$labels\n",
    "    fold_iter           = unique(folds$fold)\n",
    "    accuracy_fold       = numeric(length(fold_iter))\n",
    "\n",
    "    res                 = getXY(fold_iter[i],folds,inputs,labels)\n",
    "    X                   = res$X\n",
    "    X.val               = res$X.val\n",
    "    y.lower             = res$y.lower\n",
    "    y.lower.val         = res$y.lower.val\n",
    "    y.upper             = res$y.upper\n",
    "    y.upper.val         = res$y.upper.val\n",
    "    train.folds         = cut(seq(1,nrow(X)),breaks=5,labels=FALSE)\n",
    "    res                 = list()\n",
    "    cv_folds            = KFold(y.upper, nfolds = 5,\n",
    "                                stratified = FALSE, seed = 0)\n",
    "    dtrain = xgb.DMatrix(X)\n",
    "    setinfo(dtrain,'label_lower_bound', y.lower)\n",
    "    setinfo(dtrain,'label_upper_bound', y.upper)\n",
    "    \n",
    "    opt_res = BayesianOptimization(xgb_cv_bayes,\n",
    "                                bounds = bounds,\n",
    "                                init_grid_dt = NULL, init_points = 10, n_iter = 20,\n",
    "                                acq = \"ucb\", kappa = 2.576, eps = 0.0,\n",
    "                                verbose = TRUE)\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
